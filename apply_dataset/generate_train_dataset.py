"""
æœ¬æ–‡ä»¶ç”¨äºç”Ÿæˆæœºå™¨äººå¸å–ä»»åŠ¡çš„è®­ç»ƒæ•°æ®é›†ï¼Œå°†å¤šæ¨¡æ€æ•°æ®è½¬æ¢ä¸ºH5æ ¼å¼ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. æ•´åˆå¤šç§æ•°æ®æºï¼šæ·±åº¦å›¾åƒã€åˆ†å‰²å›¾åƒã€ç‰©ä½“ä½å§¿çœŸå€¼ã€ç‰©ä½“å°ºå¯¸æ ‡ç­¾
2. é€šè¿‡H5DataGeneratorå¤„ç†åŸå§‹æ•°æ®ï¼Œç”Ÿæˆç»Ÿä¸€æ ¼å¼çš„è®­ç»ƒæ•°æ®é›†
3. æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªå¾ªç¯(cycle)å’Œåœºæ™¯(scene)çš„æ•°æ®
4. ç”Ÿæˆçš„H5æ•°æ®é›†åŒ…å«ç‚¹äº‘ã€æ³•å‘é‡ã€å„ç§å¸å–è¯„åˆ†ç­‰ä¿¡æ¯

æ•°æ®æµç¨‹ï¼š
è¾“å…¥æ•°æ®ï¼š
- æ·±åº¦å›¾åƒ(depth_images): PNGæ ¼å¼ï¼Œç”¨äº3Dç‚¹äº‘é‡å»º
- åˆ†å‰²å›¾åƒ(segment_images): EXRæ ¼å¼ï¼ŒåŒ…å«ç‰©ä½“åˆ†å‰²ä¿¡æ¯å’ŒID
- ç‰©ä½“ä½å§¿çœŸå€¼(gt): CSVæ ¼å¼ï¼ŒåŒ…å«ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„6Dä½å§¿
- ç‰©ä½“å°ºå¯¸æ ‡ç­¾(individual_object_size): CSVæ ¼å¼ï¼Œç‰©ä½“å¯è§é¢ç§¯æ¯”ä¾‹ä¿¡æ¯

è¾“å‡ºæ•°æ®ï¼š
- H5æ•°æ®é›†æ–‡ä»¶ï¼šåŒ…å«ç‚¹äº‘åæ ‡ã€æ³•å‘é‡ã€å¯†å°è¯„åˆ†ã€æŠ—æ‰­è¯„åˆ†ã€å¯è¡Œæ€§è¯„åˆ†ç­‰

åº”ç”¨åœºæ™¯ï¼š
- æœºå™¨äººæŠ“å–å’Œå¸å–ä»»åŠ¡çš„æ·±åº¦å­¦ä¹ è®­ç»ƒ
- å¤šæ¨¡æ€æ„ŸçŸ¥æ•°æ®çš„é¢„å¤„ç†å’Œæ ‡å‡†åŒ–
- å¤§è§„æ¨¡ä»¿çœŸæ•°æ®é›†çš„ç”Ÿæˆå’Œç®¡ç†

@author: Huang Dingtao
@checked: Huang Dingtao
"""
import os
# è®¾ç½®CUDAå¯è§è®¾å¤‡ä¸ºGPU 0ï¼Œç”¨äºåŠ é€Ÿæ•°æ®å¤„ç†ä¸­çš„æ·±åº¦å­¦ä¹ è®¡ç®—
os.environ["CUDA_VISIBLE_DEVICES"] = '0'
# import torch
# test = torch.randn(30, 3).cuda()  # GPUæµ‹è¯•ä»£ç ï¼ˆå·²æ³¨é‡Šï¼‰

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'config'))
from camera_info import CameraInfo
import argparse
import re
import OpenEXR
import Imath
import numpy as np
import gc
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from datetime import datetime
import cv2
    
# å¯¼å…¥H5æ•°æ®ç”Ÿæˆå™¨æ¨¡å—ï¼ŒåŒ…å«æ‰€æœ‰æ•°æ®å¤„ç†çš„æ ¸å¿ƒåŠŸèƒ½
from H5DataGenerator import *

# å‘½ä»¤è¡Œå‚æ•°è§£æ
parser = argparse.ArgumentParser()
# æ•°æ®é›†æ ¹ç›®å½•
parser.add_argument('--data_dir', type=str, default='G:/Diffusion_Suction_DataSet', help='æ•°æ®é›†æ ¹ç›®å½•')
parser.add_argument('--cycle_list', type=str, required=True, help='å¾ªç¯ç¼–å·ï¼Œæ”¯æŒæ ¼å¼: "5"(å•ä¸ª), "[1,10]"(åŒºé—´), "{1,3,5}"(åˆ—è¡¨)')
parser.add_argument('--scene_list', type=str, required=True, help='åœºæ™¯ç¼–å·ï¼Œæ”¯æŒæ ¼å¼: "5"(å•ä¸ª), "[1,10]"(åŒºé—´), "{1,3,5}"(åˆ—è¡¨)')
parser.add_argument('--camera_info_file', type=str, default='camera_info.yaml', help='ç›¸æœºå‚æ•°é…ç½®æ–‡ä»¶è·¯å¾„')
parser.add_argument('--parameter_file', type=str, default='parameter.json', help='æ•°æ®ç”Ÿæˆå™¨å‚æ•°é…ç½®æ–‡ä»¶è·¯å¾„')
parser.add_argument('--num_workers', type=int, default=4, help='çº¿ç¨‹æ± çš„å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 4ï¼Œå»ºè®®ä¸è¶…è¿‡GPUå†…å­˜é™åˆ¶)')
FLAGS = parser.parse_args()

def parse_range_or_single(input_str):
    """
    è§£æè¾“å…¥å­—ç¬¦ä¸²ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
    - å•ä¸ªå€¼: "5" -> [5]
    - åŒºé—´: "[1,10]" -> [1,2,3,4,5,6,7,8,9,10]
    - åˆ—è¡¨: "{1,3,5}" -> [1,3,5]
    """
    input_str = input_str.strip()
    
    # å¦‚æœæ˜¯åŒºé—´æ ¼å¼ [start,end]
    range_match = re.match(r'^\[(\d+),(\d+)\]$', input_str)
    if range_match:
        start, end = map(int, range_match.groups())
        return list(range(start, end + 1))
    
    # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ {1,3,5,7}
    list_match = re.match(r'^\{(.+)\}$', input_str)
    if list_match:
        values_str = list_match.group(1)
        return [int(x.strip()) for x in values_str.split(',')]
    
    # å¦‚æœæ˜¯å•ä¸ªæ•°å­—
    if input_str.isdigit():
        return [int(input_str)]
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼ŒæŠ›å‡ºé”™è¯¯
    raise ValueError(f"æ— æ³•è§£æè¾“å…¥æ ¼å¼: {input_str}. æ”¯æŒçš„æ ¼å¼: '5'(å•ä¸ª), '[1,10]'(åŒºé—´), '{{1,3,5}}'(åˆ—è¡¨)")

# å®šä¹‰H5æ•°æ®é›†çš„æ ¹è¾“å‡ºç›®å½•
OUT_ROOT_DIR = os.path.join(FLAGS.data_dir, 'h5_dataset')
if not os.path.exists(OUT_ROOT_DIR):
    os.makedirs(OUT_ROOT_DIR)    

# å®šä¹‰è®­ç»ƒé›†çš„è¾“å‡ºç›®å½•
TRAIN_SET_DIR = os.path.join(FLAGS.data_dir, 'train')
if not os.path.exists(TRAIN_SET_DIR):
    os.mkdir(TRAIN_SET_DIR)

# å®šä¹‰å„ç±»è¾“å…¥æ•°æ®çš„ç›®å½•è·¯å¾„
GT_DIR = os.path.join(FLAGS.data_dir, 'gt')  # çœŸå€¼æ ‡ç­¾ç›®å½•ï¼šç‰©ä½“6Dä½å§¿ç­‰ground truthæ•°æ®
SEGMENT_DIR = os.path.join(FLAGS.data_dir, 'segment_images')  # åˆ†å‰²å›¾åƒç›®å½•ï¼šEXRæ ¼å¼ï¼ŒåŒ…å«ç‰©ä½“IDå’Œåˆ†å‰²æ©ç 
DEPTH_DIR = os.path.join(FLAGS.data_dir, 'depth_images')  # æ·±åº¦å›¾åƒç›®å½•ï¼šPNGæ ¼å¼ï¼Œç”¨äº3Dç‚¹äº‘é‡å»º
OBJ_PATH = os.path.join(FLAGS.data_dir, 'OBJ')  # 3Dç‰©ä½“æ¨¡å‹ç›®å½•ï¼šåŒ…å«OBJæ ¼å¼çš„ç‰©ä½“å‡ ä½•æ¨¡å‹
GT_PATH = os.path.join(FLAGS.data_dir, 'gt')  # çœŸå€¼æ•°æ®è·¯å¾„ï¼šCSVæ ¼å¼çš„ç‰©ä½“ä½å§¿æ ‡æ³¨
INDIVIDUA_PATH = os.path.join(FLAGS.data_dir, 'individual_object_size')  # å•ä¸ªç‰©ä½“å°ºå¯¸æ ‡ç­¾ç›®å½•ï¼šç‰©ä½“å¯è§é¢ç§¯æ¯”ä¾‹æ•°æ®

# ç”¨OpenEXRè¯»å–EXRåˆ†å‰²å›¾åƒ
def read_exr_to_numpy(filepath):
    exr_file = OpenEXR.InputFile(filepath)
    header = exr_file.header()
    dw = header['dataWindow']
    width = dw.max.x - dw.min.x + 1
    height = dw.max.y - dw.min.y + 1
    channels = ['R', 'G', 'B']
    pt = Imath.PixelType(Imath.PixelType.FLOAT)
    data = [np.frombuffer(exr_file.channel(c, pt), dtype=np.float32) for c in channels]
    img = np.stack([d.reshape(height, width) for d in data], axis=-1)
    return img

# çº¿ç¨‹å®‰å…¨çš„æ‰“å°é”
print_lock = threading.Lock()

def thread_safe_print(message):
    """çº¿ç¨‹å®‰å…¨çš„æ‰“å°å‡½æ•°"""
    with print_lock:
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {message}")

def process_single_cycle_scene(cycle_id, scene_id, data_generator_params):
    """
    å¤„ç†å•ä¸ªå¾ªç¯-åœºæ™¯ç»„åˆï¼Œç”ŸæˆH5è®­ç»ƒæ•°æ®
    
    Args:
        cycle_id (int): å¾ªç¯ç¼–å·
        scene_id (int): åœºæ™¯ç¼–å·
        data_generator_params (dict): H5æ•°æ®ç”Ÿæˆå™¨çš„å‚æ•°é…ç½®
        
    Returns:
        tuple: (cycle_id, scene_id, success, error_msg)
    """
    try:
        thread_safe_print(f"å¼€å§‹å¤„ç†å¾ªç¯ {cycle_id}ï¼Œåœºæ™¯ {scene_id}")
        
        # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„H5æ•°æ®ç”Ÿæˆå™¨å®ä¾‹ï¼Œé¿å…çº¿ç¨‹å†²çª
        g = H5DataGenerator(
            params_file_name=data_generator_params['parameter_file'], 
            camera_info_file_name=data_generator_params['camera_info_file'], 
            objs_path=data_generator_params['objs_path'],
            target_num_point=16384,
            test_flag=False
        )
        
        # 1. æ„å»ºæ·±åº¦å›¾åƒæ–‡ä»¶è·¯å¾„å¹¶åŠ è½½
        depth_image_path = os.path.join(
            data_generator_params['depth_dir'], 
            'cycle_{:0>4}'.format(cycle_id), 
            "{:0>3}".format(scene_id), 
            'Image0001.png'
        )
        depth_image = cv2.imread(depth_image_path, cv2.IMREAD_UNCHANGED)
        if depth_image is None:
            raise ValueError(f"æ— æ³•è¯»å–æ·±åº¦å›¾åƒæ–‡ä»¶: {depth_image_path}")
    
        # 2. æ„å»ºåˆ†å‰²å›¾åƒæ–‡ä»¶è·¯å¾„å¹¶åŠ è½½
        seg_img_path = os.path.join(
            data_generator_params['segment_dir'], 
            'cycle_{:0>4}'.format(cycle_id), 
            "{:0>3}".format(scene_id), 
            'Image0001.exr'
        )
        segment_image = read_exr_to_numpy(seg_img_path)

        # 3. æ„å»ºçœŸå€¼æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        gt_file_path = os.path.join(
            data_generator_params['gt_path'], 
            'cycle_{:0>4}'.format(cycle_id), 
            "{:0>3}".format(scene_id), 
            '{:0>3}.csv'.format(scene_id)
        )

        # 4. æ„å»ºè¾“å‡ºH5æ–‡ä»¶è·¯å¾„
        out_cycle_dir = os.path.join(
            data_generator_params['train_set_dir'], 
            'cycle_{:0>4}'.format(cycle_id)
        )
        if not os.path.exists(out_cycle_dir):
            os.makedirs(out_cycle_dir, exist_ok=True)
        
        output_h5_path = os.path.join(out_cycle_dir, "{:0>3}.h5".format(scene_id))

        # 5. æ„å»ºå•ä¸ªç‰©ä½“å°ºå¯¸æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        individual_object_size_path = os.path.join(
            data_generator_params['individual_path'], 
            'cycle_{:0>4}'.format(cycle_id), 
            "{:0>3}".format(scene_id), 
            '{:0>3}.csv'.format(scene_id)
        )

        # 6. æ ¸å¿ƒå¤„ç†æ­¥éª¤ï¼šè°ƒç”¨æ•°æ®ç”Ÿæˆå™¨å¤„ç†å½“å‰åœºæ™¯
        g.process_train_set(
            depth_image, segment_image, gt_file_path, 
            output_h5_path, individual_object_size_path
        )
        
        thread_safe_print(f"âœ… å®Œæˆå¤„ç†å¾ªç¯ {cycle_id}ï¼Œåœºæ™¯ {scene_id}")
        gc.collect()  # æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        return (cycle_id, scene_id, True, None)
        
    except Exception as e:
        error_msg = f"å¾ªç¯ {cycle_id}ï¼Œåœºæ™¯ {scene_id} å¤„ç†å¤±è´¥: {str(e)}"
        thread_safe_print(f"âŒ {error_msg}")
        return (cycle_id, scene_id, False, error_msg)

if __name__ == "__main__":
    import time
    start_time = time.time()
    
    # è§£æå¾ªç¯å’Œåœºæ™¯ç¼–å·ä¸ºæ•´æ•°åˆ—è¡¨
    CYCLE_idx_list = parse_range_or_single(FLAGS.cycle_list)
    SCENE_idx_list = parse_range_or_single(FLAGS.scene_list)

    # å‡†å¤‡æ•°æ®ç”Ÿæˆå™¨å‚æ•°é…ç½®
    data_generator_params = {
        'parameter_file': FLAGS.parameter_file,
        'camera_info_file': FLAGS.camera_info_file,
        'objs_path': os.path.join(FLAGS.data_dir, 'OBJ'),
        'depth_dir': DEPTH_DIR,
        'segment_dir': SEGMENT_DIR,
        'gt_path': GT_PATH,
        'train_set_dir': TRAIN_SET_DIR,
        'individual_path': INDIVIDUA_PATH
    }
    
    # ç”Ÿæˆæ‰€æœ‰å¾ªç¯-åœºæ™¯ç»„åˆ
    tasks = []
    for cycle_id in CYCLE_idx_list:
        for scene_id in SCENE_idx_list:
            tasks.append((cycle_id, scene_id))
    
    total_tasks = len(tasks)
    completed_tasks = 0
    failed_tasks = []
    
    print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"   æ•°æ®ç›®å½•: {FLAGS.data_dir}")
    print(f"   å¾ªç¯åˆ—è¡¨: {CYCLE_idx_list}")
    print(f"   åœºæ™¯åˆ—è¡¨: {SCENE_idx_list}")
    print(f"   å·¥ä½œçº¿ç¨‹æ•°: {FLAGS.num_workers}")
    print(f"   æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print()
    
    thread_safe_print(f"ğŸš€ å¼€å§‹å¤„ç† {total_tasks} ä¸ªå¾ªç¯-åœºæ™¯ç»„åˆï¼Œä½¿ç”¨ {FLAGS.num_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=FLAGS.num_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_task = {
            executor.submit(process_single_cycle_scene, cycle_id, scene_id, data_generator_params): (cycle_id, scene_id)
            for cycle_id, scene_id in tasks
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_task):
            cycle_id, scene_id = future_to_task[future]
            try:
                result_cycle_id, result_scene_id, success, error_msg = future.result()
                completed_tasks += 1
                
                if success:
                    # è®¡ç®—è¿›åº¦
                    progress = completed_tasks / total_tasks * 100
                    thread_safe_print(f"ğŸ“Š è¿›åº¦: {completed_tasks}/{total_tasks} ({progress:.1f}%) - å¾ªç¯{result_cycle_id:04d}-åœºæ™¯{result_scene_id:03d}")
                else:
                    failed_tasks.append((result_cycle_id, result_scene_id, error_msg))
                    
            except Exception as e:
                completed_tasks += 1
                error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                failed_tasks.append((cycle_id, scene_id, error_msg))
                thread_safe_print(f"âŒ å¾ªç¯ {cycle_id}ï¼Œåœºæ™¯ {scene_id} æ‰§è¡Œå¼‚å¸¸: {e}")
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    thread_safe_print(f"\nğŸ“ˆ å¤„ç†å®Œæˆç»Ÿè®¡:")
    thread_safe_print(f"   æ€»ä»»åŠ¡æ•°: {total_tasks}")
    thread_safe_print(f"   æˆåŠŸä»»åŠ¡: {completed_tasks - len(failed_tasks)}")
    thread_safe_print(f"   å¤±è´¥ä»»åŠ¡: {len(failed_tasks)}")
    thread_safe_print(f"   æ€»è€—æ—¶: {elapsed_time:.2f} ç§’ ({elapsed_time/60:.1f} åˆ†é’Ÿ)")
    
    if total_tasks > 0:
        avg_time_per_task = elapsed_time / total_tasks
        thread_safe_print(f"   å¹³å‡æ¯ä»»åŠ¡: {avg_time_per_task:.2f} ç§’")
    
    if failed_tasks:
        thread_safe_print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡åˆ—è¡¨:")
        for cycle_id, scene_id, error_msg in failed_tasks:
            thread_safe_print(f"   å¾ªç¯{cycle_id:04d}-åœºæ™¯{scene_id:03d}: {error_msg}")
        
        # å°†å¤±è´¥çš„ä»»åŠ¡ä¿å­˜åˆ°æ–‡ä»¶
        error_log_file = os.path.join(OUT_ROOT_DIR, 'generation_errors.txt')
        with open(error_log_file, 'w', encoding='utf-8') as f:
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¤±è´¥ä»»åŠ¡æ•°: {len(failed_tasks)}\n\n")
            for cycle_id, scene_id, error_msg in failed_tasks:
                f.write(f"å¾ªç¯{cycle_id:04d}-åœºæ™¯{scene_id:03d}: {error_msg}\n")
        thread_safe_print(f"ğŸ“ å¤±è´¥ä»»åŠ¡å·²è®°å½•åˆ°: {error_log_file}")
    else:
        thread_safe_print(f"ğŸ‰ æ‰€æœ‰è®­ç»ƒæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")

